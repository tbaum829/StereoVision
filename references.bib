@article{barnes2009patchmatch,
  abstract = {This paper presents interactive image editing tools using a new randomized algorithm for quickly finding approximate nearest neighbor matches between image patches. Previous research in graphics and vision has leveraged such nearest-neighbor searches to provide a variety of high-level digital image editing tools. However, the cost of computing a field of such matches for an entire image has eluded previous efforts to provide interactive performance. Our algorithm offers substantial performance improvements over the previous state of the art (20-100x), enabling its use in interactive editing tools. The key insights driving the algorithm are that some good patch matches can be found via random sampling, and that natural coherence in the imagery allows us to propagate such matches quickly to surrounding areas. We offer theoretical analysis of the convergence properties of the algorithm, as well as empirical and practical evidence for its high quality and performance. This one simple algorithm forms the basis for a variety of tools – image retargeting, completion and reshuffling – that can be used together in the context of a high-level image editing application. Finally, we propose additional intuitive constraints on the synthesis process that offer the user a level of control unavailable in previous methods.},
  author = {Barnes, Connelly and Shechtman, Eli and Finkelstein, Adam and Goldman, Dan B},
  journal = {ACM Transactions on Graphics (Proc. SIGGRAPH)},
  number = {3},
  title = {PatchMatch: A Randomized Correspondence Algorithm for Structural Image Editing},
  volume = {28},
  year = {2009},
  note = {1749 citations},
  url = {https://gfx.cs.princeton.edu/pubs/Barnes_2009_PAR/patchmatch.pdf}
}
@article{luo2016efficient,
  abstract = {In the past year, convolutional neural networks have been shown to perform extremely well for stereo estimation. However, current architectures rely on siamese networks which exploit concatenation followed by further processing layers, requiring a minute of GPU computation per image pair. In contrast, in this paper we propose a matching network which is able to produce very accurate results in less than a second of GPU computation. Towards this goal,we exploit a product layer which simply computes the inner product between the two representations of a siamese architecture. We train our network by treating the problem as multi-class classification, where the classes are all possible disparities. This allows us to get calibrated scores, which result in much better matching performance when compared to existing approaches.},
  author = {Luo, Wenjie and Schwing, Alexander G. and Urtasun, Raquel},
  journal = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages = {5695-5703},
  title = {Efficient Deep Learning for Stereo Matching},
  year = {2016},
  note = {291 citations},
  url = {https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Luo_Efficient_Deep_Learning_CVPR_2016_paper.pdf}
}
@article{duggal2019deeppruner,
  abstract = {Our goal is to significantly speed up the runtime of current state-of-the-art stereo algorithms to enable real-time inference. Towards this goal, we developed a differentiable PatchMatch module that allows us to discard most disparities without requiring full cost volume evaluation. We then exploit this representation to learn which range to prune for each pixel. By progressively reducing the search space and effectively propagating such information, we are able to efficiently compute the cost volume for high likelihood hypotheses and achieve savings in both memory and computation. Finally, an image guided refinement module is exploited to further improve the performance. Since all our components are differentiable, the full network can be trained end-to-end. Our experiments show that our method achieves competitive results on KITTI and SceneFlow datasets while running in real-time at 62ms.},
  author = {Duggal, Shivam and Wang, Shenlong and Ma, Wei-Chiu and Hu, Rui and Urtasun, Raquel},
  journal = {International Conference on Computer Vision (ICCV)},
  pages = {4321-4330},
  title = {DeepPruner: Learning Efficient Stereo Matching via Differentiable PatchMatch},
  year = {2019},
  note = {0 citations},
  url = {http://www.cs.toronto.edu/~slwang/deeppruner.pdf}
}
@inproceedings{mayer2016large,
  title={A large dataset to train convolutional networks for disparity, optical flow, and scene flow estimation},
  author={Mayer, Nikolaus and Ilg, Eddy and Hausser, Philip and Fischer, Philipp and Cremers, Daniel and Dosovitskiy, Alexey and Brox, Thomas},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={4040--4048},
  year={2016}
}
@inproceedings{geiger2012we,
  title={Are we ready for autonomous driving? the kitti vision benchmark suite},
  author={Geiger, Andreas and Lenz, Philip and Urtasun, Raquel},
  booktitle={2012 IEEE Conference on Computer Vision and Pattern Recognition},
  pages={3354--3361},
  year={2012},
  organization={IEEE}
}
@inproceedings{tonioni2019real,
  title={Real-time self-adaptive deep stereo},
  author={Tonioni, Alessio and Tosi, Fabio and Poggi, Matteo and Mattoccia, Stefano and Stefano, Luigi Di},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={195--204},
  year={2019}
}
@inproceedings{einecke2015multi,
  title={A multi-block-matching approach for stereo},
  author={Einecke, Nils and Eggert, Julian},
  booktitle={2015 IEEE Intelligent Vehicles Symposium (IV)},
  pages={585--592},
  year={2015},
  organization={IEEE}
}
@inproceedings{yamaguchi2014efficient,
  title={Efficient joint segmentation, occlusion labeling, stereo and flow estimation},
  author={Yamaguchi, Koichiro and McAllester, David and Urtasun, Raquel},
  booktitle={European Conference on Computer Vision},
  pages={756--771},
  year={2014},
  organization={Springer}
}
@article{zbontar2016stereo,
  title={Stereo Matching by Training a Convolutional Neural Network to Compare Image Patches.},
  author={Zbontar, Jure and LeCun, Yann and others},
  journal={Journal of Machine Learning Research},
  volume={17},
  number={1-32},
  pages={2},
  year={2016}
}
@inproceedings{guney2015displets,
  title={Displets: Resolving stereo ambiguities using object knowledge},
  author={Guney, Fatma and Geiger, Andreas},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={4165--4175},
  year={2015}
}